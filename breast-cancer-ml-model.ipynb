{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b112cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117044fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>70</td>\n",
       "      <td>2.707</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>8.8071</td>\n",
       "      <td>9.702400</td>\n",
       "      <td>7.99585</td>\n",
       "      <td>417.114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>20.690495</td>\n",
       "      <td>92</td>\n",
       "      <td>3.115</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>8.8438</td>\n",
       "      <td>5.429285</td>\n",
       "      <td>4.06405</td>\n",
       "      <td>468.786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>23.124670</td>\n",
       "      <td>91</td>\n",
       "      <td>4.498</td>\n",
       "      <td>1.009651</td>\n",
       "      <td>17.9393</td>\n",
       "      <td>22.432040</td>\n",
       "      <td>9.27715</td>\n",
       "      <td>554.697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>21.367521</td>\n",
       "      <td>77</td>\n",
       "      <td>3.226</td>\n",
       "      <td>0.612725</td>\n",
       "      <td>9.8827</td>\n",
       "      <td>7.169560</td>\n",
       "      <td>12.76600</td>\n",
       "      <td>928.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>92</td>\n",
       "      <td>3.549</td>\n",
       "      <td>0.805386</td>\n",
       "      <td>6.6994</td>\n",
       "      <td>4.819240</td>\n",
       "      <td>10.57635</td>\n",
       "      <td>773.920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age        BMI  Glucose  Insulin      HOMA   Leptin  Adiponectin  Resistin  \\\n",
       "0   48  23.500000       70    2.707  0.467409   8.8071     9.702400   7.99585   \n",
       "1   83  20.690495       92    3.115  0.706897   8.8438     5.429285   4.06405   \n",
       "2   82  23.124670       91    4.498  1.009651  17.9393    22.432040   9.27715   \n",
       "3   68  21.367521       77    3.226  0.612725   9.8827     7.169560  12.76600   \n",
       "4   86  21.111111       92    3.549  0.805386   6.6994     4.819240  10.57635   \n",
       "\n",
       "     MCP.1  Classification  \n",
       "0  417.114               1  \n",
       "1  468.786               1  \n",
       "2  554.697               1  \n",
       "3  928.220               1  \n",
       "4  773.920               1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = pd.read_csv('dataR2.csv', header=0)\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc0d9e",
   "metadata": {},
   "source": [
    " PRELIMINARY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5478a24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Age         BMI     Glucose     Insulin        HOMA      Leptin  \\\n",
      "count  116.000000  116.000000  116.000000  116.000000  116.000000  116.000000   \n",
      "mean    57.301724   27.582111   97.793103   10.012086    2.694988   26.615080   \n",
      "std     16.112766    5.020136   22.525162   10.067768    3.642043   19.183294   \n",
      "min     24.000000   18.370000   60.000000    2.432000    0.467409    4.311000   \n",
      "25%     45.000000   22.973205   85.750000    4.359250    0.917966   12.313675   \n",
      "50%     56.000000   27.662416   92.000000    5.924500    1.380939   20.271000   \n",
      "75%     71.000000   31.241442  102.000000   11.189250    2.857787   37.378300   \n",
      "max     89.000000   38.578759  201.000000   58.460000   25.050342   90.280000   \n",
      "\n",
      "       Adiponectin    Resistin        MCP.1  Classification  \n",
      "count   116.000000  116.000000   116.000000      116.000000  \n",
      "mean     10.180874   14.725966   534.647000        1.551724  \n",
      "std       6.843341   12.390646   345.912663        0.499475  \n",
      "min       1.656020    3.210000    45.843000        1.000000  \n",
      "25%       5.474283    6.881763   269.978250        1.000000  \n",
      "50%       8.352692   10.827740   471.322500        2.000000  \n",
      "75%      11.815970   17.755207   700.085000        2.000000  \n",
      "max      38.040000   82.100000  1698.440000        2.000000  \n",
      "Age               0\n",
      "BMI               0\n",
      "Glucose           0\n",
      "Insulin           0\n",
      "HOMA              0\n",
      "Leptin            0\n",
      "Adiponectin       0\n",
      "Resistin          0\n",
      "MCP.1             0\n",
      "Classification    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(cancer.describe())# there is great standard deviatiom in some of the variables (give example)\n",
    "#meaning that some form of normalisation or standardisation could be useful\n",
    "print(cancer.isnull().sum()) #no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd416283",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = cancer.corr()\n",
    "sns.heatmap(corr_matrix, annot = True)\n",
    "plt.show()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dca049",
   "metadata": {},
   "source": [
    "FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb8b67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.plotting.parallel_coordinates(\n",
    " cancer, 'Classification', color=('#556270', '#4ECDC4')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "336e17f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.iloc[:,0:10]\n",
    "cancer_mod = cancer.drop(['Leptin','HOMA'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "799c5ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>70</td>\n",
       "      <td>2.707</td>\n",
       "      <td>9.702400</td>\n",
       "      <td>7.99585</td>\n",
       "      <td>417.114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>20.690495</td>\n",
       "      <td>92</td>\n",
       "      <td>3.115</td>\n",
       "      <td>5.429285</td>\n",
       "      <td>4.06405</td>\n",
       "      <td>468.786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>23.124670</td>\n",
       "      <td>91</td>\n",
       "      <td>4.498</td>\n",
       "      <td>22.432040</td>\n",
       "      <td>9.27715</td>\n",
       "      <td>554.697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>21.367521</td>\n",
       "      <td>77</td>\n",
       "      <td>3.226</td>\n",
       "      <td>7.169560</td>\n",
       "      <td>12.76600</td>\n",
       "      <td>928.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>92</td>\n",
       "      <td>3.549</td>\n",
       "      <td>4.819240</td>\n",
       "      <td>10.57635</td>\n",
       "      <td>773.920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>45</td>\n",
       "      <td>26.850000</td>\n",
       "      <td>92</td>\n",
       "      <td>3.330</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>10.96000</td>\n",
       "      <td>268.230</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>62</td>\n",
       "      <td>26.840000</td>\n",
       "      <td>100</td>\n",
       "      <td>4.530</td>\n",
       "      <td>21.420000</td>\n",
       "      <td>7.32000</td>\n",
       "      <td>330.160</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>65</td>\n",
       "      <td>32.050000</td>\n",
       "      <td>97</td>\n",
       "      <td>5.730</td>\n",
       "      <td>22.540000</td>\n",
       "      <td>10.33000</td>\n",
       "      <td>314.050</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>72</td>\n",
       "      <td>25.590000</td>\n",
       "      <td>82</td>\n",
       "      <td>2.820</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>3.27000</td>\n",
       "      <td>392.460</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>86</td>\n",
       "      <td>27.180000</td>\n",
       "      <td>138</td>\n",
       "      <td>19.910</td>\n",
       "      <td>14.110000</td>\n",
       "      <td>4.35000</td>\n",
       "      <td>90.090</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age        BMI  Glucose  Insulin  Adiponectin  Resistin    MCP.1  \\\n",
       "0     48  23.500000       70    2.707     9.702400   7.99585  417.114   \n",
       "1     83  20.690495       92    3.115     5.429285   4.06405  468.786   \n",
       "2     82  23.124670       91    4.498    22.432040   9.27715  554.697   \n",
       "3     68  21.367521       77    3.226     7.169560  12.76600  928.220   \n",
       "4     86  21.111111       92    3.549     4.819240  10.57635  773.920   \n",
       "..   ...        ...      ...      ...          ...       ...      ...   \n",
       "111   45  26.850000       92    3.330    12.100000  10.96000  268.230   \n",
       "112   62  26.840000      100    4.530    21.420000   7.32000  330.160   \n",
       "113   65  32.050000       97    5.730    22.540000  10.33000  314.050   \n",
       "114   72  25.590000       82    2.820    33.750000   3.27000  392.460   \n",
       "115   86  27.180000      138   19.910    14.110000   4.35000   90.090   \n",
       "\n",
       "     Classification  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "..              ...  \n",
       "111               2  \n",
       "112               2  \n",
       "113               2  \n",
       "114               2  \n",
       "115               2  \n",
       "\n",
       "[116 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aab23006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((73, 7), (73,), (24, 7), (24,), (19, 7), (19,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(cancer_mod.iloc[:, 0:7], \n",
    "                                                   cancer['Classification'],\n",
    "                                                   test_size = 0.20,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,\n",
    "                                                  y_train,\n",
    "                                                  test_size = 0.20,\n",
    "                                                  random_state = 0)\n",
    "\n",
    "x_train.shape,y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab7c77b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>92</td>\n",
       "      <td>3.549</td>\n",
       "      <td>4.819240</td>\n",
       "      <td>10.57635</td>\n",
       "      <td>773.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>51</td>\n",
       "      <td>27.688778</td>\n",
       "      <td>77</td>\n",
       "      <td>3.855</td>\n",
       "      <td>3.192090</td>\n",
       "      <td>10.37518</td>\n",
       "      <td>473.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>65</td>\n",
       "      <td>29.666548</td>\n",
       "      <td>85</td>\n",
       "      <td>14.649</td>\n",
       "      <td>7.282870</td>\n",
       "      <td>19.46324</td>\n",
       "      <td>1698.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>43</td>\n",
       "      <td>34.422174</td>\n",
       "      <td>89</td>\n",
       "      <td>23.194</td>\n",
       "      <td>8.300955</td>\n",
       "      <td>6.71026</td>\n",
       "      <td>960.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>34</td>\n",
       "      <td>24.242424</td>\n",
       "      <td>92</td>\n",
       "      <td>21.699</td>\n",
       "      <td>21.823745</td>\n",
       "      <td>12.06534</td>\n",
       "      <td>481.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>64</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>98</td>\n",
       "      <td>5.700</td>\n",
       "      <td>4.783985</td>\n",
       "      <td>13.91245</td>\n",
       "      <td>395.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>43</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>103</td>\n",
       "      <td>4.328</td>\n",
       "      <td>12.718960</td>\n",
       "      <td>38.65310</td>\n",
       "      <td>775.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>36</td>\n",
       "      <td>28.576676</td>\n",
       "      <td>86</td>\n",
       "      <td>4.345</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>9.15390</td>\n",
       "      <td>534.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>43</td>\n",
       "      <td>26.562500</td>\n",
       "      <td>101</td>\n",
       "      <td>10.555</td>\n",
       "      <td>6.420295</td>\n",
       "      <td>16.10000</td>\n",
       "      <td>806.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>67</td>\n",
       "      <td>29.606767</td>\n",
       "      <td>79</td>\n",
       "      <td>5.819</td>\n",
       "      <td>2.194280</td>\n",
       "      <td>4.20750</td>\n",
       "      <td>585.307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age        BMI  Glucose  Insulin  Adiponectin  Resistin     MCP.1\n",
       "4    86  21.111111       92    3.549     4.819240  10.57635   773.920\n",
       "34   51  27.688778       77    3.855     3.192090  10.37518   473.859\n",
       "85   65  29.666548       85   14.649     7.282870  19.46324  1698.440\n",
       "33   43  34.422174       89   23.194     8.300955   6.71026   960.246\n",
       "55   34  24.242424       92   21.699    21.823745  12.06534   481.949\n",
       "..  ...        ...      ...      ...          ...       ...       ...\n",
       "67   64  22.222222       98    5.700     4.783985  13.91245   395.976\n",
       "77   43  31.250000      103    4.328    12.718960  38.65310   775.322\n",
       "20   36  28.576676       86    4.345     8.600000   9.15390   534.224\n",
       "75   43  26.562500      101   10.555     6.420295  16.10000   806.724\n",
       "35   67  29.606767       79    5.819     2.194280   4.20750   585.307\n",
       "\n",
       "[73 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f14868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2ddc5f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n  Accuracy  Precision        F1\n",
       "0  1  0.684211   0.555556  0.625000\n",
       "1  2  0.631579   0.500000  0.666667\n",
       "2  3  0.631579   0.500000  0.631579\n",
       "3  4  0.578947   0.461538  0.600000\n",
       "4  5  0.684211   0.545455  0.666667\n",
       "5  6  0.526316   0.428571  0.571429\n",
       "6  7  0.684211   0.545455  0.666667\n",
       "7  8  0.631579   0.500000  0.631579\n",
       "8  9  0.473684   0.333333  0.375000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "\n",
    "k = []\n",
    "weight_knn = []\n",
    "acc_knn = []\n",
    "prec_knn = []\n",
    "f1_knn = []\n",
    "\n",
    "\n",
    "uniform_df = pd.DataFrame(columns = [\"n\", \"Accuracy\", \"Precision\", \"F1\"])\n",
    "distance_df = pd.DataFrame(columns = [\"n\", \"Accuracy\", \"Precision\", \"F1\"])\n",
    "\n",
    " \n",
    "# Pre-processing of data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(x_train)\n",
    "scaler.fit(x_val)\n",
    "\n",
    "\n",
    "X_Norm_train=scaler.transform(x_train)\n",
    "X_Norm_val = scaler.transform(x_val)\n",
    "\n",
    "\n",
    "y_Norm_train= y_train\n",
    "y_Norm_val = y_val\n",
    "\n",
    "\n",
    "for weights in [\"uniform\", \"distance\"]:\n",
    "    for i in range(1,10):\n",
    "        k.append(i)\n",
    "        knn_clf = neighbors.KNeighborsClassifier(n_neighbors = i, weights=weights)\n",
    "        knn_clf.fit(X_Norm_train, y_Norm_train)\n",
    "        knn_pred=knn_clf.predict(X_Norm_val)\n",
    "        \n",
    "        acc_knn.append(accuracy_score(y_Norm_val, knn_pred))\n",
    "        prec_knn.append(precision_score(y_Norm_val, knn_pred))\n",
    "        f1_knn.append(f1_score(y_Norm_val, knn_pred))\n",
    "\n",
    "uniform_df[\"n\"] = k[0:9]\n",
    "uniform_df[\"Accuracy\"] = acc_knn[0:9]\n",
    "uniform_df[\"Precision\"] = prec_knn[0:9]\n",
    "uniform_df[\"F1\"] = f1_knn[0:9]\n",
    "\n",
    "distance_df[\"n\"] = k[9:18]\n",
    "distance_df[\"Accuracy\"] = acc_knn[9:18]\n",
    "distance_df[\"Precision\"] = prec_knn[9:18]\n",
    "distance_df[\"F1\"] = f1_knn[9:18]\n",
    "\n",
    "uniform_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c921c6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n  Accuracy  Precision        F1\n",
       "0  1  0.684211   0.555556  0.625000\n",
       "1  2  0.684211   0.555556  0.625000\n",
       "2  3  0.578947   0.461538  0.600000\n",
       "3  4  0.631579   0.500000  0.631579\n",
       "4  5  0.631579   0.500000  0.631579\n",
       "5  6  0.631579   0.500000  0.631579\n",
       "6  7  0.631579   0.500000  0.631579\n",
       "7  8  0.684211   0.545455  0.666667\n",
       "8  9  0.631579   0.500000  0.631579"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ce2b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##From both tables, it can be seen that the highest accuracy and F1 is achieved\n",
    "## when k =5 at uniform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2315513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " uniform:\n",
      "acuracy is:0.875\n",
      "precision is:0.8333333333333334\n",
      "F1 is:0.8695652173913043\n",
      "\n",
      " distance:\n",
      "acuracy is:0.875\n",
      "precision is:0.8333333333333334\n",
      "F1 is:0.8695652173913043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler.fit(x_test)\n",
    "X_Norm_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "y_Norm_test = y_test\n",
    "\n",
    "n_neighbors=5\n",
    "\n",
    "for weights in [\"uniform\", \"distance\"]:\n",
    "    opt_knn_clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    opt_knn_clf.fit(X_Norm_train, y_Norm_train)\n",
    "    opt_knn_pred=opt_knn_clf.predict(X_Norm_test)\n",
    "    print(f' {weights}:')\n",
    "    print(f'acuracy is:{accuracy_score(y_Norm_test, opt_knn_pred)}')\n",
    "    print(f'precision is:{precision_score(y_Norm_test, opt_knn_pred)}')\n",
    "    print(f'F1 is:{f1_score(y_Norm_test, opt_knn_pred)}\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d19e7a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((73, 7), (73,), (24, 7), (24,), (19, 7), (19,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d1f287",
   "metadata": {},
   "source": [
    "Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02301245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "acc_dt = []\n",
    "prec_dt = []\n",
    "f1_dt = []\n",
    "depth = []\n",
    "sample = []\n",
    "criteria = []\n",
    "\n",
    "for a in [\"entropy\", \"gini\"]:\n",
    "    for b in range(1,12):\n",
    "        for c in range(1,12):\n",
    "            dt =DecisionTreeClassifier(criterion=a,random_state=0, max_depth=b, min_samples_leaf=c)\n",
    "            dt.fit(x_train,y_train)\n",
    "            dt_pred_val=dt.predict(x_val)\n",
    "            \n",
    "            criteria.append(a)\n",
    "            depth.append(b)\n",
    "            sample.append(c)\n",
    "            acc_dt.append(accuracy_score(y_val, dt_pred_val))\n",
    "            prec_dt.append(precision_score(y_val, dt_pred_val))\n",
    "            f1_dt.append(f1_score(y_val, dt_pred_val, average='micro'))\n",
    "\n",
    "\n",
    "data_dt = {\"Depth\" : depth , \n",
    "           \"Sample\" : sample, \n",
    "           \"Accuracy\" : acc_dt,\n",
    "           \"Precision\" : prec_dt, \n",
    "           \"F1\" : f1_dt, \n",
    "           \"Criterion\" : criteria}\n",
    "\n",
    "dt_df = pd.DataFrame(data = data_dt)\n",
    "\n",
    "dt_df.loc[dt_df[\"Accuracy\"] == dt_df[\"Accuracy\"].max()]\n",
    "\n",
    "print(type(y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc103b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>Sample</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Criterion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Depth  Sample  Accuracy  Precision        F1 Criterion\n",
       "25       3       4  0.684211   0.555556  0.684211   entropy\n",
       "26       3       5  0.684211   0.555556  0.684211   entropy\n",
       "27       3       6  0.684211   0.555556  0.684211   entropy\n",
       "33       4       1  0.684211   0.555556  0.684211   entropy\n",
       "34       4       2  0.684211   0.555556  0.684211   entropy\n",
       "35       4       3  0.684211   0.555556  0.684211   entropy\n",
       "44       5       1  0.684211   0.555556  0.684211   entropy\n",
       "45       5       2  0.684211   0.555556  0.684211   entropy\n",
       "55       6       1  0.684211   0.555556  0.684211   entropy\n",
       "56       6       2  0.684211   0.555556  0.684211   entropy\n",
       "66       7       1  0.684211   0.555556  0.684211   entropy\n",
       "67       7       2  0.684211   0.555556  0.684211   entropy\n",
       "77       8       1  0.684211   0.555556  0.684211   entropy\n",
       "78       8       2  0.684211   0.555556  0.684211   entropy\n",
       "88       9       1  0.684211   0.555556  0.684211   entropy\n",
       "89       9       2  0.684211   0.555556  0.684211   entropy\n",
       "99      10       1  0.684211   0.555556  0.684211   entropy\n",
       "100     10       2  0.684211   0.555556  0.684211   entropy\n",
       "110     11       1  0.684211   0.555556  0.684211   entropy\n",
       "111     11       2  0.684211   0.555556  0.684211   entropy\n",
       "144      3       2  0.684211   0.555556  0.684211      gini\n",
       "145      3       3  0.684211   0.555556  0.684211      gini\n",
       "146      3       4  0.684211   0.555556  0.684211      gini\n",
       "147      3       5  0.684211   0.555556  0.684211      gini\n",
       "155      4       2  0.684211   0.555556  0.684211      gini\n",
       "156      4       3  0.684211   0.555556  0.684211      gini\n",
       "157      4       4  0.684211   0.555556  0.684211      gini\n",
       "158      4       5  0.684211   0.555556  0.684211      gini\n",
       "166      5       2  0.684211   0.555556  0.684211      gini\n",
       "167      5       3  0.684211   0.555556  0.684211      gini\n",
       "168      5       4  0.684211   0.555556  0.684211      gini\n",
       "169      5       5  0.684211   0.555556  0.684211      gini\n",
       "177      6       2  0.684211   0.555556  0.684211      gini\n",
       "178      6       3  0.684211   0.555556  0.684211      gini\n",
       "179      6       4  0.684211   0.555556  0.684211      gini\n",
       "180      6       5  0.684211   0.555556  0.684211      gini\n",
       "188      7       2  0.684211   0.555556  0.684211      gini\n",
       "189      7       3  0.684211   0.555556  0.684211      gini\n",
       "190      7       4  0.684211   0.555556  0.684211      gini\n",
       "191      7       5  0.684211   0.555556  0.684211      gini\n",
       "199      8       2  0.684211   0.555556  0.684211      gini\n",
       "200      8       3  0.684211   0.555556  0.684211      gini\n",
       "201      8       4  0.684211   0.555556  0.684211      gini\n",
       "202      8       5  0.684211   0.555556  0.684211      gini\n",
       "210      9       2  0.684211   0.555556  0.684211      gini\n",
       "211      9       3  0.684211   0.555556  0.684211      gini\n",
       "212      9       4  0.684211   0.555556  0.684211      gini\n",
       "213      9       5  0.684211   0.555556  0.684211      gini\n",
       "221     10       2  0.684211   0.555556  0.684211      gini\n",
       "222     10       3  0.684211   0.555556  0.684211      gini\n",
       "223     10       4  0.684211   0.555556  0.684211      gini\n",
       "224     10       5  0.684211   0.555556  0.684211      gini\n",
       "232     11       2  0.684211   0.555556  0.684211      gini\n",
       "233     11       3  0.684211   0.555556  0.684211      gini\n",
       "234     11       4  0.684211   0.555556  0.684211      gini\n",
       "235     11       5  0.684211   0.555556  0.684211      gini"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_df.loc[dt_df[\"Precision\"] == dt_df[\"Precision\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96c6d9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>Sample</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Criterion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Depth  Sample  Accuracy  Precision        F1 Criterion\n",
       "25       3       4  0.684211   0.555556  0.684211   entropy\n",
       "26       3       5  0.684211   0.555556  0.684211   entropy\n",
       "27       3       6  0.684211   0.555556  0.684211   entropy\n",
       "33       4       1  0.684211   0.555556  0.684211   entropy\n",
       "34       4       2  0.684211   0.555556  0.684211   entropy\n",
       "..     ...     ...       ...        ...       ...       ...\n",
       "233     11       3  0.684211   0.555556  0.684211      gini\n",
       "234     11       4  0.684211   0.555556  0.684211      gini\n",
       "235     11       5  0.684211   0.555556  0.684211      gini\n",
       "236     11       6  0.684211   0.545455  0.684211      gini\n",
       "237     11       7  0.684211   0.545455  0.684211      gini\n",
       "\n",
       "[74 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_df.loc[dt_df[\"F1\"] == dt_df[\"F1\"].max()]\n",
    "\n",
    "## it is clear that these hyperparameters achieve the best results. In order to choose the best \n",
    "## hyperparameters out of these, we need to select the minimum values to reduce the computational \n",
    "# load. There is no need choosing higher values for the depth or samples (spend more time training)\n",
    "# when the same results can be achieved with lower values\n",
    "\n",
    "## The optimaldecision tree classifier will use 'gini' as the criterion, have a maximum depth of 3\n",
    "## and a minimum sample leaf split of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a0c8f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test F1:0.7083333333333334, test acc:0.7083333333333334, test prec:0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "##Optimal Decision Tree classifier\n",
    "\n",
    "\n",
    "opt_dt_model =DecisionTreeClassifier(criterion='gini',random_state=0, max_depth=3, min_samples_leaf=2)\n",
    "opt_dt_model.fit(x_train,y_train)\n",
    "dt_pred_test=opt_dt_model.predict(x_test)\n",
    "dt_test_f1 = f1_score(y_test, dt_pred_test, average='micro')\n",
    "dt_test_acc = accuracy_score(y_test, dt_pred_test)\n",
    "dt_test_prec = precision_score(y_test, dt_pred_test)\n",
    "print(f'test F1:{dt_test_f1}, test acc:{dt_test_acc}, test prec:{dt_test_prec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e247804",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ab_f1 = []\n",
    "ab_acc = []\n",
    "ab_prec = []\n",
    "est = []\n",
    "lr = []\n",
    "ab_depth = []\n",
    "ab_samples = []\n",
    "ab_criteria = []\n",
    "\n",
    "for e in range(25, 600, 25):\n",
    "    for l in np.arange(0.1, 4.0, 0.1):\n",
    "        ab = AdaBoostClassifier(DecisionTreeClassifier(criterion='gini', random_state=0,  \n",
    "                                                       max_depth=3, min_samples_leaf=2),\n",
    "                                n_estimators = e, learning_rate = l)\n",
    "        ab.fit(x_train, y_train)\n",
    "        pred_ab = ab.predict(x_val)\n",
    "                                        \n",
    "        est.append(e)\n",
    "        lr.append(l)\n",
    "                    \n",
    "        ab_f1.append(f1_score(y_val, pred_ab, average='micro'))\n",
    "        ab_acc.append(accuracy_score(y_val, pred_ab))\n",
    "        ab_prec.append(precision_score(y_val, pred_ab))\n",
    "            \n",
    "        \n",
    "data_ab = {\"No. of estimators\" : est , \n",
    "           \"Learning rate\" : lr, \n",
    "           \"Accuracy\" : ab_acc,\n",
    "           \"Precision\" : ab_prec, \n",
    "           \"F1\" : ab_f1}\n",
    "\n",
    "ab_df = pd.DataFrame(data = data_ab)\n",
    "ab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e95331",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_df.loc[ab_df[\"Accuracy\"] == ab_df[\"Accuracy\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660515d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_df.loc[ab_df[\"Precision\"] == ab_df[\"Precision\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf5acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_df.loc[ab_df[\"F1\"] == ab_df[\"F1\"].max()]\n",
    "\n",
    "## From the results, the optimal parameters are where the number of estimators is 375 and\n",
    "## the learning rate is 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "##optimal AdaBoost\n",
    "\n",
    "## used the optimised parameters of the decision tree classifier within the optimised AdaBoost \n",
    "\n",
    "opt_ab = AdaBoostClassifier(DecisionTreeClassifier(criterion='gini', random_state=0,  max_depth=3, \n",
    "                                                   min_samples_leaf=2),\n",
    "                            n_estimators = 375, learning_rate = 0.5, random_state = 0\n",
    "                           )\n",
    "\n",
    "opt_ab.fit(x_train, y_train)\n",
    "pred_optab = opt_ab.predict(x_test)\n",
    "optab_f1 = f1_score(y_test, pred_optab, average='micro')\n",
    "optab_acc = accuracy_score(y_test, pred_optab)\n",
    "optab_prec = precision_score(y_test, pred_optab)\n",
    "print(f'test F1:{optab_f1}, test acc:{optab_acc}, test prec:{optab_prec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a01427b",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(x_train)\n",
    "scaler.fit(x_val)\n",
    "\n",
    "\n",
    "X_Norm_train=scaler.transform(x_train)\n",
    "X_Norm_val = scaler.transform(x_val)\n",
    "y_Norm_train= y_train\n",
    "y_Norm_val = y_val\n",
    "\n",
    "par_kernel = []\n",
    "par_degree = []\n",
    "par_c = []\n",
    "par_gamma = []\n",
    "\n",
    "acc_sv = []\n",
    "prec_sv = []\n",
    "f1_sv = []\n",
    "\n",
    "kernels=['linear','poly','rbf']\n",
    "for kernel in kernels: \n",
    "    for degree in range(1,10):\n",
    "        for c in [0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]:\n",
    "            for gamma in [1e-3, 1e-2, 1e-1, 1, 1e1]:\n",
    "                sv_clf = svm.SVC(kernel=kernel, degree=degree,C=c, gamma = gamma)\n",
    "                sv_clf.fit(X_Norm_train, y_Norm_train)\n",
    "                svpred_val = sv_clf.predict(X_Norm_val)\n",
    "                \n",
    "                par_kernel.append(kernel)\n",
    "                par_degree.append(degree)\n",
    "                par_c.append(c)\n",
    "                par_gamma.append(gamma)\n",
    "                \n",
    "                acc_sv.append(accuracy_score(y_Norm_val, svpred_val))\n",
    "                prec_sv.append(precision_score(y_test, svpred_test))\n",
    "                f1_sv.append(f1_score(y_test, svpred_test, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cb14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sv = {\"Kernel\" : par_kernel , \n",
    "           \"Degree\" : par_degree,\n",
    "           \"C\" : par_c,\n",
    "           \"Gamma\" : par_gamma,\n",
    "           \"Accuracy\" : acc_sv,\n",
    "           \"Precision\" : prec_sv, \n",
    "           \"F1\" : f1_sv}\n",
    "\n",
    "sv_df = pd.DataFrame(data = data_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cadd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec2344",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_df.loc[sv_df[\"Accuracy\"] == sv_df[\"Accuracy\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e4c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_df.loc[sv_df[\"F1\"] == sv_df[\"F1\"].max()]\n",
    "# shows that the optimal model is that with a 'poly' kernel, degree of 4, C value of 50, gamma value\n",
    "# of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe13c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimal SVM\n",
    "\n",
    "scaler.fit(x_test)\n",
    "X_Norm_test = scaler.transform(x_test)\n",
    "y_Norm_test = y_test\n",
    "\n",
    "opt_sv_clf = svm.SVC(kernel='poly', degree=2,C=80, gamma = 0.01)\n",
    "opt_sv_clf.fit(X_Norm_train, y_Norm_train)\n",
    "opt_svpred_test = opt_sv_clf.predict(X_Norm_test)\n",
    "\n",
    "optsv_f1 = f1_score(y_Norm_test, opt_svpred_test, average='micro')\n",
    "optsv_acc = accuracy_score(y_Norm_test, opt_svpred_test)\n",
    "optsv_prec = precision_score(y_test, opt_svpred_test)\n",
    "print(f'test F1:{optsv_f1}, test acc:{optsv_acc}, test prec:{optsv_prec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fcd594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "knn_conf = opt_knn_clf.predict_proba(X_Norm_test)\n",
    "\n",
    "tpr, fpr, thresholds = roc_curve(y_Norm_test, knn_conf[:,1], pos_label=1)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='ROC')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b40b3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
